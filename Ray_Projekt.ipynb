{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a4c479f4-c993-493e-bfe9-b95a41243c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e59338e9-ec0a-4df8-bd04-682d28cb8c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-01-09 13:53:13</td></tr>\n",
       "<tr><td>Running for: </td><td>00:05:43.01        </td></tr>\n",
       "<tr><td>Memory:      </td><td>17.1/31.9 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=44<br>Bracket: Iter 64.000: 0.96484375 | Iter 16.000: 0.92578125 | Iter 4.000: 0.884765625 | Iter 1.000: 0.73095703125<br>Logical resource usage: 2.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  momentum</th><th style=\"text-align: right;\">      acc</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mnist_e33e1_00000</td><td>TERMINATED</td><td>127.0.0.1:38528</td><td style=\"text-align: right;\">0.000792714</td><td style=\"text-align: right;\">  0.469882</td><td style=\"text-align: right;\">0.196289 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.42563</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00001</td><td>TERMINATED</td><td>127.0.0.1:14064</td><td style=\"text-align: right;\">0.00166862 </td><td style=\"text-align: right;\">  0.155109</td><td style=\"text-align: right;\">0.288086 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.2048 </td></tr>\n",
       "<tr><td>train_mnist_e33e1_00002</td><td>TERMINATED</td><td>127.0.0.1:24988</td><td style=\"text-align: right;\">0.00219065 </td><td style=\"text-align: right;\">  0.269254</td><td style=\"text-align: right;\">0.791992 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         8.22459</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00003</td><td>TERMINATED</td><td>127.0.0.1:43528</td><td style=\"text-align: right;\">0.000373667</td><td style=\"text-align: right;\">  0.561524</td><td style=\"text-align: right;\">0.547852 </td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">        31.4575 </td></tr>\n",
       "<tr><td>train_mnist_e33e1_00004</td><td>TERMINATED</td><td>127.0.0.1:18032</td><td style=\"text-align: right;\">0.000204919</td><td style=\"text-align: right;\">  0.171918</td><td style=\"text-align: right;\">0.129883 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.23506</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00005</td><td>TERMINATED</td><td>127.0.0.1:40156</td><td style=\"text-align: right;\">0.00173261 </td><td style=\"text-align: right;\">  0.231578</td><td style=\"text-align: right;\">0.921875 </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       197.447  </td></tr>\n",
       "<tr><td>train_mnist_e33e1_00006</td><td>TERMINATED</td><td>127.0.0.1:21384</td><td style=\"text-align: right;\">0.00419464 </td><td style=\"text-align: right;\">  0.136926</td><td style=\"text-align: right;\">0.942383 </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       198.187  </td></tr>\n",
       "<tr><td>train_mnist_e33e1_00007</td><td>TERMINATED</td><td>127.0.0.1:38140</td><td style=\"text-align: right;\">0.00258761 </td><td style=\"text-align: right;\">  0.624098</td><td style=\"text-align: right;\">0.901367 </td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">        31.9017 </td></tr>\n",
       "<tr><td>train_mnist_e33e1_00008</td><td>TERMINATED</td><td>127.0.0.1:33724</td><td style=\"text-align: right;\">0.000236157</td><td style=\"text-align: right;\">  0.281247</td><td style=\"text-align: right;\">0.0966797</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.27079</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00009</td><td>TERMINATED</td><td>127.0.0.1:38672</td><td style=\"text-align: right;\">0.0017552  </td><td style=\"text-align: right;\">  0.881146</td><td style=\"text-align: right;\">0.972656 </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       198.793  </td></tr>\n",
       "<tr><td>train_mnist_e33e1_00010</td><td>TERMINATED</td><td>127.0.0.1:40108</td><td style=\"text-align: right;\">0.000796913</td><td style=\"text-align: right;\">  0.111908</td><td style=\"text-align: right;\">0.158203 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.04906</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00011</td><td>TERMINATED</td><td>127.0.0.1:25192</td><td style=\"text-align: right;\">0.00644131 </td><td style=\"text-align: right;\">  0.339702</td><td style=\"text-align: right;\">0.956055 </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       198.881  </td></tr>\n",
       "<tr><td>train_mnist_e33e1_00012</td><td>TERMINATED</td><td>127.0.0.1:40840</td><td style=\"text-align: right;\">0.000144989</td><td style=\"text-align: right;\">  0.115467</td><td style=\"text-align: right;\">0.111328 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.32579</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00013</td><td>TERMINATED</td><td>127.0.0.1:7776 </td><td style=\"text-align: right;\">0.00719607 </td><td style=\"text-align: right;\">  0.645756</td><td style=\"text-align: right;\">0.963867 </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       198.61   </td></tr>\n",
       "<tr><td>train_mnist_e33e1_00014</td><td>TERMINATED</td><td>127.0.0.1:41776</td><td style=\"text-align: right;\">0.0015467  </td><td style=\"text-align: right;\">  0.444215</td><td style=\"text-align: right;\">0.348633 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.98715</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00015</td><td>TERMINATED</td><td>127.0.0.1:12632</td><td style=\"text-align: right;\">0.000190896</td><td style=\"text-align: right;\">  0.595864</td><td style=\"text-align: right;\">0.126953 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.03877</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00016</td><td>TERMINATED</td><td>127.0.0.1:36064</td><td style=\"text-align: right;\">0.000397988</td><td style=\"text-align: right;\">  0.836723</td><td style=\"text-align: right;\">0.223633 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.0034 </td></tr>\n",
       "<tr><td>train_mnist_e33e1_00017</td><td>TERMINATED</td><td>127.0.0.1:15124</td><td style=\"text-align: right;\">0.000794328</td><td style=\"text-align: right;\">  0.234503</td><td style=\"text-align: right;\">0.199219 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.95109</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00018</td><td>TERMINATED</td><td>127.0.0.1:35736</td><td style=\"text-align: right;\">0.00929357 </td><td style=\"text-align: right;\">  0.339606</td><td style=\"text-align: right;\">0.958008 </td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">       199.172  </td></tr>\n",
       "<tr><td>train_mnist_e33e1_00019</td><td>TERMINATED</td><td>127.0.0.1:43076</td><td style=\"text-align: right;\">0.000525242</td><td style=\"text-align: right;\">  0.274699</td><td style=\"text-align: right;\">0.135742 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.18629</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00020</td><td>TERMINATED</td><td>127.0.0.1:21988</td><td style=\"text-align: right;\">0.000113914</td><td style=\"text-align: right;\">  0.428814</td><td style=\"text-align: right;\">0.0732422</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.13461</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00021</td><td>TERMINATED</td><td>127.0.0.1:37600</td><td style=\"text-align: right;\">0.0048854  </td><td style=\"text-align: right;\">  0.85009 </td><td style=\"text-align: right;\">0.869141 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         7.87559</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00022</td><td>TERMINATED</td><td>127.0.0.1:36292</td><td style=\"text-align: right;\">0.00581288 </td><td style=\"text-align: right;\">  0.479314</td><td style=\"text-align: right;\">0.873047 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         8.34949</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00023</td><td>TERMINATED</td><td>127.0.0.1:20580</td><td style=\"text-align: right;\">0.00016215 </td><td style=\"text-align: right;\">  0.656065</td><td style=\"text-align: right;\">0.149414 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.12789</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00024</td><td>TERMINATED</td><td>127.0.0.1:10648</td><td style=\"text-align: right;\">0.00195072 </td><td style=\"text-align: right;\">  0.268067</td><td style=\"text-align: right;\">0.429688 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.98599</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00025</td><td>TERMINATED</td><td>127.0.0.1:21912</td><td style=\"text-align: right;\">0.00537937 </td><td style=\"text-align: right;\">  0.431662</td><td style=\"text-align: right;\">0.646484 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.00611</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00026</td><td>TERMINATED</td><td>127.0.0.1:35988</td><td style=\"text-align: right;\">0.00284607 </td><td style=\"text-align: right;\">  0.259496</td><td style=\"text-align: right;\">0.191406 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.08328</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00027</td><td>TERMINATED</td><td>127.0.0.1:36760</td><td style=\"text-align: right;\">0.00441512 </td><td style=\"text-align: right;\">  0.493973</td><td style=\"text-align: right;\">0.859375 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         7.76863</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00028</td><td>TERMINATED</td><td>127.0.0.1:18032</td><td style=\"text-align: right;\">0.00323808 </td><td style=\"text-align: right;\">  0.693506</td><td style=\"text-align: right;\">0.895508 </td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">        32.5527 </td></tr>\n",
       "<tr><td>train_mnist_e33e1_00029</td><td>TERMINATED</td><td>127.0.0.1:19712</td><td style=\"text-align: right;\">0.0067145  </td><td style=\"text-align: right;\">  0.543666</td><td style=\"text-align: right;\">0.583984 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.02103</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00030</td><td>TERMINATED</td><td>127.0.0.1:16176</td><td style=\"text-align: right;\">0.00884591 </td><td style=\"text-align: right;\">  0.224805</td><td style=\"text-align: right;\">0.956055 </td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">       124.921  </td></tr>\n",
       "<tr><td>train_mnist_e33e1_00031</td><td>TERMINATED</td><td>127.0.0.1:23164</td><td style=\"text-align: right;\">0.00099299 </td><td style=\"text-align: right;\">  0.184461</td><td style=\"text-align: right;\">0.0917969</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.15943</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00032</td><td>TERMINATED</td><td>127.0.0.1:42556</td><td style=\"text-align: right;\">0.000128265</td><td style=\"text-align: right;\">  0.15737 </td><td style=\"text-align: right;\">0.0664062</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.03291</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00033</td><td>TERMINATED</td><td>127.0.0.1:37772</td><td style=\"text-align: right;\">0.000277702</td><td style=\"text-align: right;\">  0.164385</td><td style=\"text-align: right;\">0.0478516</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.03869</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00034</td><td>TERMINATED</td><td>127.0.0.1:32916</td><td style=\"text-align: right;\">0.000150269</td><td style=\"text-align: right;\">  0.54061 </td><td style=\"text-align: right;\">0.161133 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.09089</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00035</td><td>TERMINATED</td><td>127.0.0.1:36660</td><td style=\"text-align: right;\">0.00928948 </td><td style=\"text-align: right;\">  0.336379</td><td style=\"text-align: right;\">0.861328 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         8.25628</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00036</td><td>TERMINATED</td><td>127.0.0.1:37664</td><td style=\"text-align: right;\">0.000982414</td><td style=\"text-align: right;\">  0.695648</td><td style=\"text-align: right;\">0.261719 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.27134</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00037</td><td>TERMINATED</td><td>127.0.0.1:21988</td><td style=\"text-align: right;\">0.000168816</td><td style=\"text-align: right;\">  0.803927</td><td style=\"text-align: right;\">0.103516 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.10119</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00038</td><td>TERMINATED</td><td>127.0.0.1:41588</td><td style=\"text-align: right;\">0.00136788 </td><td style=\"text-align: right;\">  0.130493</td><td style=\"text-align: right;\">0.125    </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.24185</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00039</td><td>TERMINATED</td><td>127.0.0.1:35228</td><td style=\"text-align: right;\">0.00628901 </td><td style=\"text-align: right;\">  0.229561</td><td style=\"text-align: right;\">0.693359 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.06033</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00040</td><td>TERMINATED</td><td>127.0.0.1:12656</td><td style=\"text-align: right;\">0.00242404 </td><td style=\"text-align: right;\">  0.750572</td><td style=\"text-align: right;\">0.454102 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.05003</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00041</td><td>TERMINATED</td><td>127.0.0.1:42200</td><td style=\"text-align: right;\">0.000195571</td><td style=\"text-align: right;\">  0.487606</td><td style=\"text-align: right;\">0.117188 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.18508</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00042</td><td>TERMINATED</td><td>127.0.0.1:40216</td><td style=\"text-align: right;\">0.00944003 </td><td style=\"text-align: right;\">  0.784851</td><td style=\"text-align: right;\">0.964844 </td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">        96.8313 </td></tr>\n",
       "<tr><td>train_mnist_e33e1_00043</td><td>TERMINATED</td><td>127.0.0.1:39968</td><td style=\"text-align: right;\">0.00348912 </td><td style=\"text-align: right;\">  0.40933 </td><td style=\"text-align: right;\">0.875977 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         8.05502</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00044</td><td>TERMINATED</td><td>127.0.0.1:39992</td><td style=\"text-align: right;\">0.00108151 </td><td style=\"text-align: right;\">  0.511825</td><td style=\"text-align: right;\">0.255859 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.20592</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00045</td><td>TERMINATED</td><td>127.0.0.1:14076</td><td style=\"text-align: right;\">0.00402522 </td><td style=\"text-align: right;\">  0.879424</td><td style=\"text-align: right;\">0.961914 </td><td style=\"text-align: right;\">    64</td><td style=\"text-align: right;\">        97.1425 </td></tr>\n",
       "<tr><td>train_mnist_e33e1_00046</td><td>TERMINATED</td><td>127.0.0.1:1680 </td><td style=\"text-align: right;\">0.000709095</td><td style=\"text-align: right;\">  0.300169</td><td style=\"text-align: right;\">0.126953 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.11489</td></tr>\n",
       "<tr><td>train_mnist_e33e1_00047</td><td>TERMINATED</td><td>127.0.0.1:17644</td><td style=\"text-align: right;\">0.00132133 </td><td style=\"text-align: right;\">  0.492357</td><td style=\"text-align: right;\">0.244141 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2.1379 </td></tr>\n",
       "<tr><td>train_mnist_e33e1_00048</td><td>TERMINATED</td><td>127.0.0.1:39832</td><td style=\"text-align: right;\">0.00614578 </td><td style=\"text-align: right;\">  0.613915</td><td style=\"text-align: right;\">0.917969 </td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">        26.1424 </td></tr>\n",
       "<tr><td>train_mnist_e33e1_00049</td><td>TERMINATED</td><td>127.0.0.1:43528</td><td style=\"text-align: right;\">0.00134121 </td><td style=\"text-align: right;\">  0.252015</td><td style=\"text-align: right;\">0.326172 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1.73875</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 13:53:13,026\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'C:/Users/froti/ray_results/exp' in 0.0552s.\n",
      "2025-01-09 13:53:13,038\tINFO tune.py:1041 -- Total run time: 343.04 seconds (342.95 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning time: 343.14 seconds\n",
      "Best config is: {'lr': 0.0017551968239715395, 'momentum': 0.8811457906279782}\n",
      "Best accuracy is: 0.97265625\n",
      "Total execution time: 348.24 seconds\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import tempfile\n",
    "import time  # Import the time module\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from filelock import FileLock\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import ray\n",
    "from ray import train, tune\n",
    "from ray.train import Checkpoint\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "\n",
    "# Change these values if you want the training to run quicker or slower.\n",
    "EPOCH_SIZE = 6000\n",
    "TEST_SIZE = 1000\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 3, kernel_size=3)\n",
    "        self.fc = nn.Linear(192, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 3))\n",
    "        x = x.view(-1, 192)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "def train_func(model, optimizer, train_loader, device=None):\n",
    "    device = device or torch.device(\"cpu\")\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if batch_idx * len(data) > EPOCH_SIZE:\n",
    "            return\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def test_func(model, data_loader, device=None):\n",
    "    device = device or torch.device(\"cpu\")\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            if batch_idx * len(data) > TEST_SIZE:\n",
    "                break\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "def get_data_loaders(batch_size=64):\n",
    "    mnist_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "    )\n",
    "\n",
    "    # We add FileLock here because multiple workers will want to\n",
    "    # download data, and this may cause overwrites since\n",
    "    # DataLoader is not threadsafe.\n",
    "    with FileLock(os.path.expanduser(\"~/data.lock\")):\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST(\n",
    "                \"~/data\", train=True, download=True, transform=mnist_transforms\n",
    "            ),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST(\n",
    "                \"~/data\", train=False, download=True, transform=mnist_transforms\n",
    "            ),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def train_mnist(config):\n",
    "    should_checkpoint = config.get(\"should_checkpoint\", False)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    train_loader, test_loader = get_data_loaders()\n",
    "    model = ConvNet().to(device)\n",
    "\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"]\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "        train_func(model, optimizer, train_loader, device)\n",
    "        acc = test_func(model, test_loader, device)\n",
    "        metrics = {\"mean_accuracy\": acc}\n",
    "\n",
    "        # Report metrics (and possibly a checkpoint)\n",
    "        if should_checkpoint:\n",
    "            with tempfile.TemporaryDirectory() as tempdir:\n",
    "                torch.save(model.state_dict(), os.path.join(tempdir, \"model.pt\"))\n",
    "                train.report(metrics, checkpoint=Checkpoint.from_directory(tempdir))\n",
    "        else:\n",
    "            train.report(metrics)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()  # Start measuring time\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"PyTorch MNIST Example\")\n",
    "    parser.add_argument(\n",
    "        \"--cuda\", action=\"store_true\", default=False, help=\"Enables GPU training\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--smoke-test\", action=\"store_true\", help=\"Finish quickly for testing\"\n",
    "    )\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    # Initialize Ray with 16 CPUs\n",
    "    ray_init_start = time.time()  # Time for Ray initialization\n",
    "    ray.init(num_cpus=16)  # Use all 16 CPUs\n",
    "    ray_init_end = time.time()\n",
    "    print(f\"Ray initialization time: {ray_init_end - ray_init_start:.2f} seconds\")\n",
    "\n",
    "    # for early stopping\n",
    "    sched = AsyncHyperBandScheduler()\n",
    "\n",
    "    # Allocate resources for each trial\n",
    "    resources_per_trial = {\"cpu\": 2, \"gpu\": int(args.cuda)}  # Allocate 2 CPUs per trial\n",
    "\n",
    "    tuner_start = time.time()  # Time for tuning\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(train_mnist, resources=resources_per_trial),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"mean_accuracy\",\n",
    "            mode=\"max\",\n",
    "            scheduler=sched,\n",
    "            num_samples=50,  # Number of trials to run\n",
    "        ),\n",
    "        run_config=train.RunConfig(\n",
    "            name=\"exp\",\n",
    "            stop={\n",
    "                \"mean_accuracy\": 0.98,\n",
    "                \"training_iteration\": 100,  # Train for 100 iterations\n",
    "            },\n",
    "        ),\n",
    "        param_space={\n",
    "            \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "            \"momentum\": tune.uniform(0.1, 0.9),\n",
    "        },\n",
    "    )\n",
    "    results = tuner.fit()\n",
    "    tuner_end = time.time()\n",
    "    print(f\"Tuning time: {tuner_end - tuner_start:.2f} seconds\")\n",
    "\n",
    "    best_result = results.get_best_result()\n",
    "    print(\"Best config is:\", best_result.config)\n",
    "    print(\"Best accuracy is:\", best_result.metrics[\"mean_accuracy\"])\n",
    "\n",
    "    assert not results.errors\n",
    "\n",
    "    total_time = time.time() - start_time  # Total script time\n",
    "    print(f\"Total execution time: {total_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0820cd13-2627-4b61-9b9c-65513151b7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1/50\n",
      "Epoch 1, Accuracy: 0.8047\n",
      "Epoch 2, Accuracy: 0.8809\n",
      "Epoch 3, Accuracy: 0.8828\n",
      "Epoch 4, Accuracy: 0.8857\n",
      "Epoch 5, Accuracy: 0.8945\n",
      "Epoch 6, Accuracy: 0.8984\n",
      "Epoch 7, Accuracy: 0.9121\n",
      "Epoch 8, Accuracy: 0.9170\n",
      "Epoch 9, Accuracy: 0.9150\n",
      "Epoch 10, Accuracy: 0.9219\n",
      "Epoch 11, Accuracy: 0.9219\n",
      "Epoch 12, Accuracy: 0.9268\n",
      "Epoch 13, Accuracy: 0.9404\n",
      "Epoch 14, Accuracy: 0.9238\n",
      "Epoch 15, Accuracy: 0.9258\n",
      "Epoch 16, Accuracy: 0.9365\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 1 ran for 16 epochs.\n",
      "Trial 2/50\n",
      "Epoch 1, Accuracy: 0.7812\n",
      "Epoch 2, Accuracy: 0.8506\n",
      "Epoch 3, Accuracy: 0.8633\n",
      "Epoch 4, Accuracy: 0.8887\n",
      "Epoch 5, Accuracy: 0.8789\n",
      "Epoch 6, Accuracy: 0.9102\n",
      "Epoch 7, Accuracy: 0.8994\n",
      "Epoch 8, Accuracy: 0.9004\n",
      "Epoch 9, Accuracy: 0.9121\n",
      "Epoch 10, Accuracy: 0.9033\n",
      "Epoch 11, Accuracy: 0.9160\n",
      "Epoch 12, Accuracy: 0.9170\n",
      "Epoch 13, Accuracy: 0.8955\n",
      "Epoch 14, Accuracy: 0.9209\n",
      "Epoch 15, Accuracy: 0.9307\n",
      "Epoch 16, Accuracy: 0.9150\n",
      "Epoch 17, Accuracy: 0.9346\n",
      "Epoch 18, Accuracy: 0.9307\n",
      "Epoch 19, Accuracy: 0.9248\n",
      "Epoch 20, Accuracy: 0.9238\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 2 ran for 20 epochs.\n",
      "Trial 3/50\n",
      "Epoch 1, Accuracy: 0.0352\n",
      "Epoch 2, Accuracy: 0.0518\n",
      "Epoch 3, Accuracy: 0.0859\n",
      "Epoch 4, Accuracy: 0.0977\n",
      "Epoch 5, Accuracy: 0.1445\n",
      "Epoch 6, Accuracy: 0.1660\n",
      "Epoch 7, Accuracy: 0.1846\n",
      "Epoch 8, Accuracy: 0.2705\n",
      "Epoch 9, Accuracy: 0.3008\n",
      "Epoch 10, Accuracy: 0.3467\n",
      "Epoch 11, Accuracy: 0.4004\n",
      "Epoch 12, Accuracy: 0.4551\n",
      "Epoch 13, Accuracy: 0.4902\n",
      "Epoch 14, Accuracy: 0.5459\n",
      "Epoch 15, Accuracy: 0.5693\n",
      "Epoch 16, Accuracy: 0.6260\n",
      "Epoch 17, Accuracy: 0.6504\n",
      "Epoch 18, Accuracy: 0.6641\n",
      "Epoch 19, Accuracy: 0.6914\n",
      "Epoch 20, Accuracy: 0.6885\n",
      "Epoch 21, Accuracy: 0.7227\n",
      "Epoch 22, Accuracy: 0.7520\n",
      "Epoch 23, Accuracy: 0.7510\n",
      "Epoch 24, Accuracy: 0.7617\n",
      "Epoch 25, Accuracy: 0.7510\n",
      "Epoch 26, Accuracy: 0.7812\n",
      "Epoch 27, Accuracy: 0.7842\n",
      "Epoch 28, Accuracy: 0.8037\n",
      "Epoch 29, Accuracy: 0.8008\n",
      "Epoch 30, Accuracy: 0.8105\n",
      "Epoch 31, Accuracy: 0.8193\n",
      "Epoch 32, Accuracy: 0.7998\n",
      "Epoch 33, Accuracy: 0.8154\n",
      "Epoch 34, Accuracy: 0.8145\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 3 ran for 34 epochs.\n",
      "Trial 4/50\n",
      "Epoch 1, Accuracy: 0.3516\n",
      "Epoch 2, Accuracy: 0.5762\n",
      "Epoch 3, Accuracy: 0.7598\n",
      "Epoch 4, Accuracy: 0.8281\n",
      "Epoch 5, Accuracy: 0.8496\n",
      "Epoch 6, Accuracy: 0.8516\n",
      "Epoch 7, Accuracy: 0.8740\n",
      "Epoch 8, Accuracy: 0.8799\n",
      "Epoch 9, Accuracy: 0.8779\n",
      "Epoch 10, Accuracy: 0.8818\n",
      "Epoch 11, Accuracy: 0.8955\n",
      "Epoch 12, Accuracy: 0.9014\n",
      "Epoch 13, Accuracy: 0.9082\n",
      "Epoch 14, Accuracy: 0.8965\n",
      "Epoch 15, Accuracy: 0.9092\n",
      "Epoch 16, Accuracy: 0.8955\n",
      "Epoch 17, Accuracy: 0.9141\n",
      "Epoch 18, Accuracy: 0.8984\n",
      "Epoch 19, Accuracy: 0.9092\n",
      "Epoch 20, Accuracy: 0.9014\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 4 ran for 20 epochs.\n",
      "Trial 5/50\n",
      "Epoch 1, Accuracy: 0.4053\n",
      "Epoch 2, Accuracy: 0.6982\n",
      "Epoch 3, Accuracy: 0.8008\n",
      "Epoch 4, Accuracy: 0.8252\n",
      "Epoch 5, Accuracy: 0.8389\n",
      "Epoch 6, Accuracy: 0.8555\n",
      "Epoch 7, Accuracy: 0.8701\n",
      "Epoch 8, Accuracy: 0.8730\n",
      "Epoch 9, Accuracy: 0.8486\n",
      "Epoch 10, Accuracy: 0.8750\n",
      "Epoch 11, Accuracy: 0.8945\n",
      "Epoch 12, Accuracy: 0.8867\n",
      "Epoch 13, Accuracy: 0.8789\n",
      "Epoch 14, Accuracy: 0.8682\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 5 ran for 14 epochs.\n",
      "Trial 6/50\n",
      "Epoch 1, Accuracy: 0.7598\n",
      "Epoch 2, Accuracy: 0.8486\n",
      "Epoch 3, Accuracy: 0.8564\n",
      "Epoch 4, Accuracy: 0.8633\n",
      "Epoch 5, Accuracy: 0.8740\n",
      "Epoch 6, Accuracy: 0.8799\n",
      "Epoch 7, Accuracy: 0.8818\n",
      "Epoch 8, Accuracy: 0.8936\n",
      "Epoch 9, Accuracy: 0.9111\n",
      "Epoch 10, Accuracy: 0.9082\n",
      "Epoch 11, Accuracy: 0.9053\n",
      "Epoch 12, Accuracy: 0.8848\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 6 ran for 12 epochs.\n",
      "Trial 7/50\n",
      "Epoch 1, Accuracy: 0.8242\n",
      "Epoch 2, Accuracy: 0.8672\n",
      "Epoch 3, Accuracy: 0.8525\n",
      "Epoch 4, Accuracy: 0.8662\n",
      "Epoch 5, Accuracy: 0.8877\n",
      "Epoch 6, Accuracy: 0.8994\n",
      "Epoch 7, Accuracy: 0.8838\n",
      "Epoch 8, Accuracy: 0.9072\n",
      "Epoch 9, Accuracy: 0.8994\n",
      "Epoch 10, Accuracy: 0.9102\n",
      "Epoch 11, Accuracy: 0.9082\n",
      "Epoch 12, Accuracy: 0.9023\n",
      "Epoch 13, Accuracy: 0.9189\n",
      "Epoch 14, Accuracy: 0.9229\n",
      "Epoch 15, Accuracy: 0.9082\n",
      "Epoch 16, Accuracy: 0.9326\n",
      "Epoch 17, Accuracy: 0.9258\n",
      "Epoch 18, Accuracy: 0.9355\n",
      "Epoch 19, Accuracy: 0.9268\n",
      "Epoch 20, Accuracy: 0.9355\n",
      "Epoch 21, Accuracy: 0.9326\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 7 ran for 21 epochs.\n",
      "Trial 8/50\n",
      "Epoch 1, Accuracy: 0.1172\n",
      "Epoch 2, Accuracy: 0.1680\n",
      "Epoch 3, Accuracy: 0.2363\n",
      "Epoch 4, Accuracy: 0.2559\n",
      "Epoch 5, Accuracy: 0.2871\n",
      "Epoch 6, Accuracy: 0.3408\n",
      "Epoch 7, Accuracy: 0.4053\n",
      "Epoch 8, Accuracy: 0.4355\n",
      "Epoch 9, Accuracy: 0.4805\n",
      "Epoch 10, Accuracy: 0.5244\n",
      "Epoch 11, Accuracy: 0.5654\n",
      "Epoch 12, Accuracy: 0.5840\n",
      "Epoch 13, Accuracy: 0.6523\n",
      "Epoch 14, Accuracy: 0.6855\n",
      "Epoch 15, Accuracy: 0.7344\n",
      "Epoch 16, Accuracy: 0.7354\n",
      "Epoch 17, Accuracy: 0.7754\n",
      "Epoch 18, Accuracy: 0.7695\n",
      "Epoch 19, Accuracy: 0.7803\n",
      "Epoch 20, Accuracy: 0.7783\n",
      "Epoch 21, Accuracy: 0.7939\n",
      "Epoch 22, Accuracy: 0.8115\n",
      "Epoch 23, Accuracy: 0.8125\n",
      "Epoch 24, Accuracy: 0.8398\n",
      "Epoch 25, Accuracy: 0.8438\n",
      "Epoch 26, Accuracy: 0.8115\n",
      "Epoch 27, Accuracy: 0.8447\n",
      "Epoch 28, Accuracy: 0.8428\n",
      "Epoch 29, Accuracy: 0.8359\n",
      "Epoch 30, Accuracy: 0.8467\n",
      "Epoch 31, Accuracy: 0.8359\n",
      "Epoch 32, Accuracy: 0.8516\n",
      "Epoch 33, Accuracy: 0.8389\n",
      "Epoch 34, Accuracy: 0.8545\n",
      "Epoch 35, Accuracy: 0.8633\n",
      "Epoch 36, Accuracy: 0.8643\n",
      "Epoch 37, Accuracy: 0.8535\n",
      "Epoch 38, Accuracy: 0.8682\n",
      "Epoch 39, Accuracy: 0.8633\n",
      "Epoch 40, Accuracy: 0.8936\n",
      "Epoch 41, Accuracy: 0.8721\n",
      "Epoch 42, Accuracy: 0.8779\n",
      "Epoch 43, Accuracy: 0.8838\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 8 ran for 43 epochs.\n",
      "Trial 9/50\n",
      "Epoch 1, Accuracy: 0.8223\n",
      "Epoch 2, Accuracy: 0.8584\n",
      "Epoch 3, Accuracy: 0.8809\n",
      "Epoch 4, Accuracy: 0.8945\n",
      "Epoch 5, Accuracy: 0.9033\n",
      "Epoch 6, Accuracy: 0.9023\n",
      "Epoch 7, Accuracy: 0.8896\n",
      "Epoch 8, Accuracy: 0.8926\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 9 ran for 8 epochs.\n",
      "Trial 10/50\n",
      "Epoch 1, Accuracy: 0.0684\n",
      "Epoch 2, Accuracy: 0.0938\n",
      "Epoch 3, Accuracy: 0.1172\n",
      "Epoch 4, Accuracy: 0.1904\n",
      "Epoch 5, Accuracy: 0.2568\n",
      "Epoch 6, Accuracy: 0.2891\n",
      "Epoch 7, Accuracy: 0.3809\n",
      "Epoch 8, Accuracy: 0.4268\n",
      "Epoch 9, Accuracy: 0.4844\n",
      "Epoch 10, Accuracy: 0.5137\n",
      "Epoch 11, Accuracy: 0.5244\n",
      "Epoch 12, Accuracy: 0.5635\n",
      "Epoch 13, Accuracy: 0.5732\n",
      "Epoch 14, Accuracy: 0.6094\n",
      "Epoch 15, Accuracy: 0.6299\n",
      "Epoch 16, Accuracy: 0.6709\n",
      "Epoch 17, Accuracy: 0.6748\n",
      "Epoch 18, Accuracy: 0.6963\n",
      "Epoch 19, Accuracy: 0.6885\n",
      "Epoch 20, Accuracy: 0.7090\n",
      "Epoch 21, Accuracy: 0.7471\n",
      "Epoch 22, Accuracy: 0.7295\n",
      "Epoch 23, Accuracy: 0.7295\n",
      "Epoch 24, Accuracy: 0.7354\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 10 ran for 24 epochs.\n",
      "Trial 11/50\n",
      "Epoch 1, Accuracy: 0.0781\n",
      "Epoch 2, Accuracy: 0.0986\n",
      "Epoch 3, Accuracy: 0.0957\n",
      "Epoch 4, Accuracy: 0.1260\n",
      "Epoch 5, Accuracy: 0.1572\n",
      "Epoch 6, Accuracy: 0.1924\n",
      "Epoch 7, Accuracy: 0.2393\n",
      "Epoch 8, Accuracy: 0.2832\n",
      "Epoch 9, Accuracy: 0.3281\n",
      "Epoch 10, Accuracy: 0.3535\n",
      "Epoch 11, Accuracy: 0.3906\n",
      "Epoch 12, Accuracy: 0.4316\n",
      "Epoch 13, Accuracy: 0.4375\n",
      "Epoch 14, Accuracy: 0.4443\n",
      "Epoch 15, Accuracy: 0.5127\n",
      "Epoch 16, Accuracy: 0.5166\n",
      "Epoch 17, Accuracy: 0.5479\n",
      "Epoch 18, Accuracy: 0.5410\n",
      "Epoch 19, Accuracy: 0.5820\n",
      "Epoch 20, Accuracy: 0.6055\n",
      "Epoch 21, Accuracy: 0.6025\n",
      "Epoch 22, Accuracy: 0.6553\n",
      "Epoch 23, Accuracy: 0.6680\n",
      "Epoch 24, Accuracy: 0.6455\n",
      "Epoch 25, Accuracy: 0.6699\n",
      "Epoch 26, Accuracy: 0.6943\n",
      "Epoch 27, Accuracy: 0.7100\n",
      "Epoch 28, Accuracy: 0.7422\n",
      "Epoch 29, Accuracy: 0.7256\n",
      "Epoch 30, Accuracy: 0.7305\n",
      "Epoch 31, Accuracy: 0.7441\n",
      "Epoch 32, Accuracy: 0.7549\n",
      "Epoch 33, Accuracy: 0.7539\n",
      "Epoch 34, Accuracy: 0.7773\n",
      "Epoch 35, Accuracy: 0.7764\n",
      "Epoch 36, Accuracy: 0.7598\n",
      "Epoch 37, Accuracy: 0.8105\n",
      "Epoch 38, Accuracy: 0.7871\n",
      "Epoch 39, Accuracy: 0.7803\n",
      "Epoch 40, Accuracy: 0.7764\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 11 ran for 40 epochs.\n",
      "Trial 12/50\n",
      "Epoch 1, Accuracy: 0.6172\n",
      "Epoch 2, Accuracy: 0.7852\n",
      "Epoch 3, Accuracy: 0.8174\n",
      "Epoch 4, Accuracy: 0.8389\n",
      "Epoch 5, Accuracy: 0.8672\n",
      "Epoch 6, Accuracy: 0.8564\n",
      "Epoch 7, Accuracy: 0.8574\n",
      "Epoch 8, Accuracy: 0.8623\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 12 ran for 8 epochs.\n",
      "Trial 13/50\n",
      "Epoch 1, Accuracy: 0.4531\n",
      "Epoch 2, Accuracy: 0.8203\n",
      "Epoch 3, Accuracy: 0.8477\n",
      "Epoch 4, Accuracy: 0.8770\n",
      "Epoch 5, Accuracy: 0.8555\n",
      "Epoch 6, Accuracy: 0.8750\n",
      "Epoch 7, Accuracy: 0.8838\n",
      "Epoch 8, Accuracy: 0.8906\n",
      "Epoch 9, Accuracy: 0.8887\n",
      "Epoch 10, Accuracy: 0.8750\n",
      "Epoch 11, Accuracy: 0.9014\n",
      "Epoch 12, Accuracy: 0.8994\n",
      "Epoch 13, Accuracy: 0.8848\n",
      "Epoch 14, Accuracy: 0.8906\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 13 ran for 14 epochs.\n",
      "Trial 14/50\n",
      "Epoch 1, Accuracy: 0.8770\n",
      "Epoch 2, Accuracy: 0.8906\n",
      "Epoch 3, Accuracy: 0.8994\n",
      "Epoch 4, Accuracy: 0.8828\n",
      "Epoch 5, Accuracy: 0.8945\n",
      "Epoch 6, Accuracy: 0.9111\n",
      "Epoch 7, Accuracy: 0.9170\n",
      "Epoch 8, Accuracy: 0.9258\n",
      "Epoch 9, Accuracy: 0.9346\n",
      "Epoch 10, Accuracy: 0.9316\n",
      "Epoch 11, Accuracy: 0.9277\n",
      "Epoch 12, Accuracy: 0.9268\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 14 ran for 12 epochs.\n",
      "Trial 15/50\n",
      "Epoch 1, Accuracy: 0.4062\n",
      "Epoch 2, Accuracy: 0.6602\n",
      "Epoch 3, Accuracy: 0.7441\n",
      "Epoch 4, Accuracy: 0.7783\n",
      "Epoch 5, Accuracy: 0.8105\n",
      "Epoch 6, Accuracy: 0.8486\n",
      "Epoch 7, Accuracy: 0.8389\n",
      "Epoch 8, Accuracy: 0.8486\n",
      "Epoch 9, Accuracy: 0.8584\n",
      "Epoch 10, Accuracy: 0.8711\n",
      "Epoch 11, Accuracy: 0.8721\n",
      "Epoch 12, Accuracy: 0.8799\n",
      "Epoch 13, Accuracy: 0.8955\n",
      "Epoch 14, Accuracy: 0.8760\n",
      "Epoch 15, Accuracy: 0.8848\n",
      "Epoch 16, Accuracy: 0.8975\n",
      "Epoch 17, Accuracy: 0.8799\n",
      "Epoch 18, Accuracy: 0.8887\n",
      "Epoch 19, Accuracy: 0.8887\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 15 ran for 19 epochs.\n",
      "Trial 16/50\n",
      "Epoch 1, Accuracy: 0.1221\n",
      "Epoch 2, Accuracy: 0.1309\n",
      "Epoch 3, Accuracy: 0.1650\n",
      "Epoch 4, Accuracy: 0.1875\n",
      "Epoch 5, Accuracy: 0.2070\n",
      "Epoch 6, Accuracy: 0.2256\n",
      "Epoch 7, Accuracy: 0.2979\n",
      "Epoch 8, Accuracy: 0.2979\n",
      "Epoch 9, Accuracy: 0.3262\n",
      "Epoch 10, Accuracy: 0.3994\n",
      "Epoch 11, Accuracy: 0.4375\n",
      "Epoch 12, Accuracy: 0.4639\n",
      "Epoch 13, Accuracy: 0.5293\n",
      "Epoch 14, Accuracy: 0.5576\n",
      "Epoch 15, Accuracy: 0.5996\n",
      "Epoch 16, Accuracy: 0.6338\n",
      "Epoch 17, Accuracy: 0.6807\n",
      "Epoch 18, Accuracy: 0.6963\n",
      "Epoch 19, Accuracy: 0.7168\n",
      "Epoch 20, Accuracy: 0.7539\n",
      "Epoch 21, Accuracy: 0.7422\n",
      "Epoch 22, Accuracy: 0.7852\n",
      "Epoch 23, Accuracy: 0.8008\n",
      "Epoch 24, Accuracy: 0.7891\n",
      "Epoch 25, Accuracy: 0.8232\n",
      "Epoch 26, Accuracy: 0.8047\n",
      "Epoch 27, Accuracy: 0.8379\n",
      "Epoch 28, Accuracy: 0.7842\n",
      "Epoch 29, Accuracy: 0.8193\n",
      "Epoch 30, Accuracy: 0.8291\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 16 ran for 30 epochs.\n",
      "Trial 17/50\n",
      "Epoch 1, Accuracy: 0.6963\n",
      "Epoch 2, Accuracy: 0.8652\n",
      "Epoch 3, Accuracy: 0.8701\n",
      "Epoch 4, Accuracy: 0.8906\n",
      "Epoch 5, Accuracy: 0.8877\n",
      "Epoch 6, Accuracy: 0.8916\n",
      "Epoch 7, Accuracy: 0.8975\n",
      "Epoch 8, Accuracy: 0.9004\n",
      "Epoch 9, Accuracy: 0.9180\n",
      "Epoch 10, Accuracy: 0.9141\n",
      "Epoch 11, Accuracy: 0.8838\n",
      "Epoch 12, Accuracy: 0.9131\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 17 ran for 12 epochs.\n",
      "Trial 18/50\n",
      "Epoch 1, Accuracy: 0.4248\n",
      "Epoch 2, Accuracy: 0.6582\n",
      "Epoch 3, Accuracy: 0.7891\n",
      "Epoch 4, Accuracy: 0.8379\n",
      "Epoch 5, Accuracy: 0.8359\n",
      "Epoch 6, Accuracy: 0.8574\n",
      "Epoch 7, Accuracy: 0.8584\n",
      "Epoch 8, Accuracy: 0.8545\n",
      "Epoch 9, Accuracy: 0.8770\n",
      "Epoch 10, Accuracy: 0.8867\n",
      "Epoch 11, Accuracy: 0.8809\n",
      "Epoch 12, Accuracy: 0.8711\n",
      "Epoch 13, Accuracy: 0.8770\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 18 ran for 13 epochs.\n",
      "Trial 19/50\n",
      "Epoch 1, Accuracy: 0.1377\n",
      "Epoch 2, Accuracy: 0.2354\n",
      "Epoch 3, Accuracy: 0.2646\n",
      "Epoch 4, Accuracy: 0.3467\n",
      "Epoch 5, Accuracy: 0.4658\n",
      "Epoch 6, Accuracy: 0.5420\n",
      "Epoch 7, Accuracy: 0.5977\n",
      "Epoch 8, Accuracy: 0.6504\n",
      "Epoch 9, Accuracy: 0.7227\n",
      "Epoch 10, Accuracy: 0.7041\n",
      "Epoch 11, Accuracy: 0.7520\n",
      "Epoch 12, Accuracy: 0.7725\n",
      "Epoch 13, Accuracy: 0.7695\n",
      "Epoch 14, Accuracy: 0.7930\n",
      "Epoch 15, Accuracy: 0.8154\n",
      "Epoch 16, Accuracy: 0.8154\n",
      "Epoch 17, Accuracy: 0.8154\n",
      "Epoch 18, Accuracy: 0.8232\n",
      "Epoch 19, Accuracy: 0.8281\n",
      "Epoch 20, Accuracy: 0.8174\n",
      "Epoch 21, Accuracy: 0.8389\n",
      "Epoch 22, Accuracy: 0.8340\n",
      "Epoch 23, Accuracy: 0.8467\n",
      "Epoch 24, Accuracy: 0.8447\n",
      "Epoch 25, Accuracy: 0.8389\n",
      "Epoch 26, Accuracy: 0.8545\n",
      "Epoch 27, Accuracy: 0.8359\n",
      "Epoch 28, Accuracy: 0.8535\n",
      "Epoch 29, Accuracy: 0.8711\n",
      "Epoch 30, Accuracy: 0.8613\n",
      "Epoch 31, Accuracy: 0.8584\n",
      "Epoch 32, Accuracy: 0.8789\n",
      "Epoch 33, Accuracy: 0.8711\n",
      "Epoch 34, Accuracy: 0.8652\n",
      "Epoch 35, Accuracy: 0.8604\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 19 ran for 35 epochs.\n",
      "Trial 20/50\n",
      "Epoch 1, Accuracy: 0.7832\n",
      "Epoch 2, Accuracy: 0.8818\n",
      "Epoch 3, Accuracy: 0.8779\n",
      "Epoch 4, Accuracy: 0.8838\n",
      "Epoch 5, Accuracy: 0.8916\n",
      "Epoch 6, Accuracy: 0.8867\n",
      "Epoch 7, Accuracy: 0.9160\n",
      "Epoch 8, Accuracy: 0.9004\n",
      "Epoch 9, Accuracy: 0.9102\n",
      "Epoch 10, Accuracy: 0.9150\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 20 ran for 10 epochs.\n",
      "Trial 21/50\n",
      "Epoch 1, Accuracy: 0.2441\n",
      "Epoch 2, Accuracy: 0.5205\n",
      "Epoch 3, Accuracy: 0.7236\n",
      "Epoch 4, Accuracy: 0.7910\n",
      "Epoch 5, Accuracy: 0.8408\n",
      "Epoch 6, Accuracy: 0.8496\n",
      "Epoch 7, Accuracy: 0.8467\n",
      "Epoch 8, Accuracy: 0.8809\n",
      "Epoch 9, Accuracy: 0.8721\n",
      "Epoch 10, Accuracy: 0.8701\n",
      "Epoch 11, Accuracy: 0.8740\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 21 ran for 11 epochs.\n",
      "Trial 22/50\n",
      "Epoch 1, Accuracy: 0.5293\n",
      "Epoch 2, Accuracy: 0.7930\n",
      "Epoch 3, Accuracy: 0.8438\n",
      "Epoch 4, Accuracy: 0.8584\n",
      "Epoch 5, Accuracy: 0.8936\n",
      "Epoch 6, Accuracy: 0.8770\n",
      "Epoch 7, Accuracy: 0.8789\n",
      "Epoch 8, Accuracy: 0.8809\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 22 ran for 8 epochs.\n",
      "Trial 23/50\n",
      "Epoch 1, Accuracy: 0.1035\n",
      "Epoch 2, Accuracy: 0.1006\n",
      "Epoch 3, Accuracy: 0.1416\n",
      "Epoch 4, Accuracy: 0.1660\n",
      "Epoch 5, Accuracy: 0.1963\n",
      "Epoch 6, Accuracy: 0.2178\n",
      "Epoch 7, Accuracy: 0.2617\n",
      "Epoch 8, Accuracy: 0.2744\n",
      "Epoch 9, Accuracy: 0.2842\n",
      "Epoch 10, Accuracy: 0.3213\n",
      "Epoch 11, Accuracy: 0.3682\n",
      "Epoch 12, Accuracy: 0.3984\n",
      "Epoch 13, Accuracy: 0.4082\n",
      "Epoch 14, Accuracy: 0.4375\n",
      "Epoch 15, Accuracy: 0.4336\n",
      "Epoch 16, Accuracy: 0.4629\n",
      "Epoch 17, Accuracy: 0.4727\n",
      "Epoch 18, Accuracy: 0.5127\n",
      "Epoch 19, Accuracy: 0.5459\n",
      "Epoch 20, Accuracy: 0.5195\n",
      "Epoch 21, Accuracy: 0.5381\n",
      "Epoch 22, Accuracy: 0.5742\n",
      "Epoch 23, Accuracy: 0.6084\n",
      "Epoch 24, Accuracy: 0.5869\n",
      "Epoch 25, Accuracy: 0.6162\n",
      "Epoch 26, Accuracy: 0.6592\n",
      "Epoch 27, Accuracy: 0.6514\n",
      "Epoch 28, Accuracy: 0.6787\n",
      "Epoch 29, Accuracy: 0.6865\n",
      "Epoch 30, Accuracy: 0.7168\n",
      "Epoch 31, Accuracy: 0.6992\n",
      "Epoch 32, Accuracy: 0.6777\n",
      "Epoch 33, Accuracy: 0.7227\n",
      "Epoch 34, Accuracy: 0.7070\n",
      "Epoch 35, Accuracy: 0.7109\n",
      "Epoch 36, Accuracy: 0.7314\n",
      "Epoch 37, Accuracy: 0.7305\n",
      "Epoch 38, Accuracy: 0.7676\n",
      "Epoch 39, Accuracy: 0.7676\n",
      "Epoch 40, Accuracy: 0.7783\n",
      "Epoch 41, Accuracy: 0.7705\n",
      "Epoch 42, Accuracy: 0.7891\n",
      "Epoch 43, Accuracy: 0.7568\n",
      "Epoch 44, Accuracy: 0.7998\n",
      "Epoch 45, Accuracy: 0.7891\n",
      "Epoch 46, Accuracy: 0.7969\n",
      "Epoch 47, Accuracy: 0.7822\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 23 ran for 47 epochs.\n",
      "Trial 24/50\n",
      "Epoch 1, Accuracy: 0.8203\n",
      "Epoch 2, Accuracy: 0.8770\n",
      "Epoch 3, Accuracy: 0.8799\n",
      "Epoch 4, Accuracy: 0.8994\n",
      "Epoch 5, Accuracy: 0.8984\n",
      "Epoch 6, Accuracy: 0.9072\n",
      "Epoch 7, Accuracy: 0.9053\n",
      "Epoch 8, Accuracy: 0.8965\n",
      "Epoch 9, Accuracy: 0.9014\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 24 ran for 9 epochs.\n",
      "Trial 25/50\n",
      "Epoch 1, Accuracy: 0.0996\n",
      "Epoch 2, Accuracy: 0.1230\n",
      "Epoch 3, Accuracy: 0.1514\n",
      "Epoch 4, Accuracy: 0.1602\n",
      "Epoch 5, Accuracy: 0.1943\n",
      "Epoch 6, Accuracy: 0.2549\n",
      "Epoch 7, Accuracy: 0.3252\n",
      "Epoch 8, Accuracy: 0.3779\n",
      "Epoch 9, Accuracy: 0.4355\n",
      "Epoch 10, Accuracy: 0.4932\n",
      "Epoch 11, Accuracy: 0.5732\n",
      "Epoch 12, Accuracy: 0.6230\n",
      "Epoch 13, Accuracy: 0.6465\n",
      "Epoch 14, Accuracy: 0.6562\n",
      "Epoch 15, Accuracy: 0.7002\n",
      "Epoch 16, Accuracy: 0.7148\n",
      "Epoch 17, Accuracy: 0.7393\n",
      "Epoch 18, Accuracy: 0.7432\n",
      "Epoch 19, Accuracy: 0.7422\n",
      "Epoch 20, Accuracy: 0.7676\n",
      "Epoch 21, Accuracy: 0.7910\n",
      "Epoch 22, Accuracy: 0.7764\n",
      "Epoch 23, Accuracy: 0.8252\n",
      "Epoch 24, Accuracy: 0.7871\n",
      "Epoch 25, Accuracy: 0.8154\n",
      "Epoch 26, Accuracy: 0.8301\n",
      "Epoch 27, Accuracy: 0.8193\n",
      "Epoch 28, Accuracy: 0.8057\n",
      "Epoch 29, Accuracy: 0.8320\n",
      "Epoch 30, Accuracy: 0.8262\n",
      "Epoch 31, Accuracy: 0.8457\n",
      "Epoch 32, Accuracy: 0.8213\n",
      "Epoch 33, Accuracy: 0.8428\n",
      "Epoch 34, Accuracy: 0.8555\n",
      "Epoch 35, Accuracy: 0.8350\n",
      "Epoch 36, Accuracy: 0.8369\n",
      "Epoch 37, Accuracy: 0.8516\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 25 ran for 37 epochs.\n",
      "Trial 26/50\n",
      "Epoch 1, Accuracy: 0.7939\n",
      "Epoch 2, Accuracy: 0.8828\n",
      "Epoch 3, Accuracy: 0.8770\n",
      "Epoch 4, Accuracy: 0.8887\n",
      "Epoch 5, Accuracy: 0.9131\n",
      "Epoch 6, Accuracy: 0.9131\n",
      "Epoch 7, Accuracy: 0.8828\n",
      "Epoch 8, Accuracy: 0.9004\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 26 ran for 8 epochs.\n",
      "Trial 27/50\n",
      "Epoch 1, Accuracy: 0.0820\n",
      "Epoch 2, Accuracy: 0.1055\n",
      "Epoch 3, Accuracy: 0.1748\n",
      "Epoch 4, Accuracy: 0.1973\n",
      "Epoch 5, Accuracy: 0.2422\n",
      "Epoch 6, Accuracy: 0.2725\n",
      "Epoch 7, Accuracy: 0.3193\n",
      "Epoch 8, Accuracy: 0.3555\n",
      "Epoch 9, Accuracy: 0.4375\n",
      "Epoch 10, Accuracy: 0.4326\n",
      "Epoch 11, Accuracy: 0.5039\n",
      "Epoch 12, Accuracy: 0.5703\n",
      "Epoch 13, Accuracy: 0.5928\n",
      "Epoch 14, Accuracy: 0.6172\n",
      "Epoch 15, Accuracy: 0.6484\n",
      "Epoch 16, Accuracy: 0.6416\n",
      "Epoch 17, Accuracy: 0.6875\n",
      "Epoch 18, Accuracy: 0.7021\n",
      "Epoch 19, Accuracy: 0.7021\n",
      "Epoch 20, Accuracy: 0.7168\n",
      "Epoch 21, Accuracy: 0.7354\n",
      "Epoch 22, Accuracy: 0.7441\n",
      "Epoch 23, Accuracy: 0.7520\n",
      "Epoch 24, Accuracy: 0.7549\n",
      "Epoch 25, Accuracy: 0.7559\n",
      "Epoch 26, Accuracy: 0.7725\n",
      "Epoch 27, Accuracy: 0.7959\n",
      "Epoch 28, Accuracy: 0.7783\n",
      "Epoch 29, Accuracy: 0.8115\n",
      "Epoch 30, Accuracy: 0.7812\n",
      "Epoch 31, Accuracy: 0.8047\n",
      "Epoch 32, Accuracy: 0.7861\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 27 ran for 32 epochs.\n",
      "Trial 28/50\n",
      "Epoch 1, Accuracy: 0.3018\n",
      "Epoch 2, Accuracy: 0.5332\n",
      "Epoch 3, Accuracy: 0.6309\n",
      "Epoch 4, Accuracy: 0.7158\n",
      "Epoch 5, Accuracy: 0.7432\n",
      "Epoch 6, Accuracy: 0.7695\n",
      "Epoch 7, Accuracy: 0.7979\n",
      "Epoch 8, Accuracy: 0.8174\n",
      "Epoch 9, Accuracy: 0.8066\n",
      "Epoch 10, Accuracy: 0.8311\n",
      "Epoch 11, Accuracy: 0.8242\n",
      "Epoch 12, Accuracy: 0.8438\n",
      "Epoch 13, Accuracy: 0.8486\n",
      "Epoch 14, Accuracy: 0.8359\n",
      "Epoch 15, Accuracy: 0.8643\n",
      "Epoch 16, Accuracy: 0.8350\n",
      "Epoch 17, Accuracy: 0.8506\n",
      "Epoch 18, Accuracy: 0.8721\n",
      "Epoch 19, Accuracy: 0.8760\n",
      "Epoch 20, Accuracy: 0.8604\n",
      "Epoch 21, Accuracy: 0.8691\n",
      "Epoch 22, Accuracy: 0.8555\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 28 ran for 22 epochs.\n",
      "Trial 29/50\n",
      "Epoch 1, Accuracy: 0.1689\n",
      "Epoch 2, Accuracy: 0.1787\n",
      "Epoch 3, Accuracy: 0.2266\n",
      "Epoch 4, Accuracy: 0.2783\n",
      "Epoch 5, Accuracy: 0.3242\n",
      "Epoch 6, Accuracy: 0.3936\n",
      "Epoch 7, Accuracy: 0.4297\n",
      "Epoch 8, Accuracy: 0.4736\n",
      "Epoch 9, Accuracy: 0.5117\n",
      "Epoch 10, Accuracy: 0.5508\n",
      "Epoch 11, Accuracy: 0.6201\n",
      "Epoch 12, Accuracy: 0.6572\n",
      "Epoch 13, Accuracy: 0.6631\n",
      "Epoch 14, Accuracy: 0.6885\n",
      "Epoch 15, Accuracy: 0.7344\n",
      "Epoch 16, Accuracy: 0.7354\n",
      "Epoch 17, Accuracy: 0.7627\n",
      "Epoch 18, Accuracy: 0.7441\n",
      "Epoch 19, Accuracy: 0.7588\n",
      "Epoch 20, Accuracy: 0.7920\n",
      "Epoch 21, Accuracy: 0.8203\n",
      "Epoch 22, Accuracy: 0.8047\n",
      "Epoch 23, Accuracy: 0.7881\n",
      "Epoch 24, Accuracy: 0.8096\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 29 ran for 24 epochs.\n",
      "Trial 30/50\n",
      "Epoch 1, Accuracy: 0.1572\n",
      "Epoch 2, Accuracy: 0.2412\n",
      "Epoch 3, Accuracy: 0.3311\n",
      "Epoch 4, Accuracy: 0.4238\n",
      "Epoch 5, Accuracy: 0.5752\n",
      "Epoch 6, Accuracy: 0.6377\n",
      "Epoch 7, Accuracy: 0.7188\n",
      "Epoch 8, Accuracy: 0.7578\n",
      "Epoch 9, Accuracy: 0.7920\n",
      "Epoch 10, Accuracy: 0.7900\n",
      "Epoch 11, Accuracy: 0.7910\n",
      "Epoch 12, Accuracy: 0.8242\n",
      "Epoch 13, Accuracy: 0.8340\n",
      "Epoch 14, Accuracy: 0.8477\n",
      "Epoch 15, Accuracy: 0.8242\n",
      "Epoch 16, Accuracy: 0.8516\n",
      "Epoch 17, Accuracy: 0.8594\n",
      "Epoch 18, Accuracy: 0.8408\n",
      "Epoch 19, Accuracy: 0.8477\n",
      "Epoch 20, Accuracy: 0.8721\n",
      "Epoch 21, Accuracy: 0.8779\n",
      "Epoch 22, Accuracy: 0.8691\n",
      "Epoch 23, Accuracy: 0.8691\n",
      "Epoch 24, Accuracy: 0.8691\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 30 ran for 24 epochs.\n",
      "Trial 31/50\n",
      "Epoch 1, Accuracy: 0.1133\n",
      "Epoch 2, Accuracy: 0.2715\n",
      "Epoch 3, Accuracy: 0.4023\n",
      "Epoch 4, Accuracy: 0.5273\n",
      "Epoch 5, Accuracy: 0.6797\n",
      "Epoch 6, Accuracy: 0.7295\n",
      "Epoch 7, Accuracy: 0.7773\n",
      "Epoch 8, Accuracy: 0.7939\n",
      "Epoch 9, Accuracy: 0.8184\n",
      "Epoch 10, Accuracy: 0.8291\n",
      "Epoch 11, Accuracy: 0.8486\n",
      "Epoch 12, Accuracy: 0.8359\n",
      "Epoch 13, Accuracy: 0.8682\n",
      "Epoch 14, Accuracy: 0.8486\n",
      "Epoch 15, Accuracy: 0.8486\n",
      "Epoch 16, Accuracy: 0.8633\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 31 ran for 16 epochs.\n",
      "Trial 32/50\n",
      "Epoch 1, Accuracy: 0.6602\n",
      "Epoch 2, Accuracy: 0.8467\n",
      "Epoch 3, Accuracy: 0.8779\n",
      "Epoch 4, Accuracy: 0.9004\n",
      "Epoch 5, Accuracy: 0.8955\n",
      "Epoch 6, Accuracy: 0.9082\n",
      "Epoch 7, Accuracy: 0.9248\n",
      "Epoch 8, Accuracy: 0.9336\n",
      "Epoch 9, Accuracy: 0.9336\n",
      "Epoch 10, Accuracy: 0.9404\n",
      "Epoch 11, Accuracy: 0.9287\n",
      "Epoch 12, Accuracy: 0.9326\n",
      "Epoch 13, Accuracy: 0.9512\n",
      "Epoch 14, Accuracy: 0.9307\n",
      "Epoch 15, Accuracy: 0.9307\n",
      "Epoch 16, Accuracy: 0.9414\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 32 ran for 16 epochs.\n",
      "Trial 33/50\n",
      "Epoch 1, Accuracy: 0.0791\n",
      "Epoch 2, Accuracy: 0.0928\n",
      "Epoch 3, Accuracy: 0.1006\n",
      "Epoch 4, Accuracy: 0.1377\n",
      "Epoch 5, Accuracy: 0.1660\n",
      "Epoch 6, Accuracy: 0.1777\n",
      "Epoch 7, Accuracy: 0.2129\n",
      "Epoch 8, Accuracy: 0.2090\n",
      "Epoch 9, Accuracy: 0.2402\n",
      "Epoch 10, Accuracy: 0.2725\n",
      "Epoch 11, Accuracy: 0.2920\n",
      "Epoch 12, Accuracy: 0.3330\n",
      "Epoch 13, Accuracy: 0.3486\n",
      "Epoch 14, Accuracy: 0.3555\n",
      "Epoch 15, Accuracy: 0.3574\n",
      "Epoch 16, Accuracy: 0.4111\n",
      "Epoch 17, Accuracy: 0.4473\n",
      "Epoch 18, Accuracy: 0.4609\n",
      "Epoch 19, Accuracy: 0.4619\n",
      "Epoch 20, Accuracy: 0.4814\n",
      "Epoch 21, Accuracy: 0.5137\n",
      "Epoch 22, Accuracy: 0.5127\n",
      "Epoch 23, Accuracy: 0.5146\n",
      "Epoch 24, Accuracy: 0.5430\n",
      "Epoch 25, Accuracy: 0.5713\n",
      "Epoch 26, Accuracy: 0.5947\n",
      "Epoch 27, Accuracy: 0.5547\n",
      "Epoch 28, Accuracy: 0.5947\n",
      "Epoch 29, Accuracy: 0.6123\n",
      "Epoch 30, Accuracy: 0.6035\n",
      "Epoch 31, Accuracy: 0.6094\n",
      "Epoch 32, Accuracy: 0.6074\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 33 ran for 32 epochs.\n",
      "Trial 34/50\n",
      "Epoch 1, Accuracy: 0.6396\n",
      "Epoch 2, Accuracy: 0.8184\n",
      "Epoch 3, Accuracy: 0.8203\n",
      "Epoch 4, Accuracy: 0.8691\n",
      "Epoch 5, Accuracy: 0.8672\n",
      "Epoch 6, Accuracy: 0.8711\n",
      "Epoch 7, Accuracy: 0.8633\n",
      "Epoch 8, Accuracy: 0.8857\n",
      "Epoch 9, Accuracy: 0.9053\n",
      "Epoch 10, Accuracy: 0.8984\n",
      "Epoch 11, Accuracy: 0.9023\n",
      "Epoch 12, Accuracy: 0.8916\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 34 ran for 12 epochs.\n",
      "Trial 35/50\n",
      "Epoch 1, Accuracy: 0.5459\n",
      "Epoch 2, Accuracy: 0.7363\n",
      "Epoch 3, Accuracy: 0.7979\n",
      "Epoch 4, Accuracy: 0.8271\n",
      "Epoch 5, Accuracy: 0.8535\n",
      "Epoch 6, Accuracy: 0.8584\n",
      "Epoch 7, Accuracy: 0.8711\n",
      "Epoch 8, Accuracy: 0.8701\n",
      "Epoch 9, Accuracy: 0.8779\n",
      "Epoch 10, Accuracy: 0.8789\n",
      "Epoch 11, Accuracy: 0.8730\n",
      "Epoch 12, Accuracy: 0.8887\n",
      "Epoch 13, Accuracy: 0.8770\n",
      "Epoch 14, Accuracy: 0.8887\n",
      "Epoch 15, Accuracy: 0.8730\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 35 ran for 15 epochs.\n",
      "Trial 36/50\n",
      "Epoch 1, Accuracy: 0.1289\n",
      "Epoch 2, Accuracy: 0.1270\n",
      "Epoch 3, Accuracy: 0.1367\n",
      "Epoch 4, Accuracy: 0.1367\n",
      "Epoch 5, Accuracy: 0.1484\n",
      "Epoch 6, Accuracy: 0.1289\n",
      "Epoch 7, Accuracy: 0.1621\n",
      "Epoch 8, Accuracy: 0.1729\n",
      "Epoch 9, Accuracy: 0.1768\n",
      "Epoch 10, Accuracy: 0.1768\n",
      "Epoch 11, Accuracy: 0.1865\n",
      "Epoch 12, Accuracy: 0.2188\n",
      "Epoch 13, Accuracy: 0.2158\n",
      "Epoch 14, Accuracy: 0.2461\n",
      "Epoch 15, Accuracy: 0.2227\n",
      "Epoch 16, Accuracy: 0.2637\n",
      "Epoch 17, Accuracy: 0.2578\n",
      "Epoch 18, Accuracy: 0.2627\n",
      "Epoch 19, Accuracy: 0.3174\n",
      "Epoch 20, Accuracy: 0.2979\n",
      "Epoch 21, Accuracy: 0.3174\n",
      "Epoch 22, Accuracy: 0.3311\n",
      "Epoch 23, Accuracy: 0.3516\n",
      "Epoch 24, Accuracy: 0.3477\n",
      "Epoch 25, Accuracy: 0.3477\n",
      "Epoch 26, Accuracy: 0.3564\n",
      "Epoch 27, Accuracy: 0.3965\n",
      "Epoch 28, Accuracy: 0.3701\n",
      "Epoch 29, Accuracy: 0.3730\n",
      "Epoch 30, Accuracy: 0.4072\n",
      "Epoch 31, Accuracy: 0.4189\n",
      "Epoch 32, Accuracy: 0.4199\n",
      "Epoch 33, Accuracy: 0.4375\n",
      "Epoch 34, Accuracy: 0.4189\n",
      "Epoch 35, Accuracy: 0.4580\n",
      "Epoch 36, Accuracy: 0.4395\n",
      "Epoch 37, Accuracy: 0.4824\n",
      "Epoch 38, Accuracy: 0.4854\n",
      "Epoch 39, Accuracy: 0.4941\n",
      "Epoch 40, Accuracy: 0.5059\n",
      "Epoch 41, Accuracy: 0.5322\n",
      "Epoch 42, Accuracy: 0.4941\n",
      "Epoch 43, Accuracy: 0.5029\n",
      "Epoch 44, Accuracy: 0.5322\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 36 ran for 44 epochs.\n",
      "Trial 37/50\n",
      "Epoch 1, Accuracy: 0.1777\n",
      "Epoch 2, Accuracy: 0.1816\n",
      "Epoch 3, Accuracy: 0.2041\n",
      "Epoch 4, Accuracy: 0.2432\n",
      "Epoch 5, Accuracy: 0.2637\n",
      "Epoch 6, Accuracy: 0.3066\n",
      "Epoch 7, Accuracy: 0.3525\n",
      "Epoch 8, Accuracy: 0.3789\n",
      "Epoch 9, Accuracy: 0.4082\n",
      "Epoch 10, Accuracy: 0.4512\n",
      "Epoch 11, Accuracy: 0.4414\n",
      "Epoch 12, Accuracy: 0.4746\n",
      "Epoch 13, Accuracy: 0.5146\n",
      "Epoch 14, Accuracy: 0.5225\n",
      "Epoch 15, Accuracy: 0.5293\n",
      "Epoch 16, Accuracy: 0.5498\n",
      "Epoch 17, Accuracy: 0.5869\n",
      "Epoch 18, Accuracy: 0.5947\n",
      "Epoch 19, Accuracy: 0.6064\n",
      "Epoch 20, Accuracy: 0.6240\n",
      "Epoch 21, Accuracy: 0.6592\n",
      "Epoch 22, Accuracy: 0.6641\n",
      "Epoch 23, Accuracy: 0.6602\n",
      "Epoch 24, Accuracy: 0.6826\n",
      "Epoch 25, Accuracy: 0.6875\n",
      "Epoch 26, Accuracy: 0.6875\n",
      "Epoch 27, Accuracy: 0.7246\n",
      "Epoch 28, Accuracy: 0.7373\n",
      "Epoch 29, Accuracy: 0.7295\n",
      "Epoch 30, Accuracy: 0.7305\n",
      "Epoch 31, Accuracy: 0.7520\n",
      "Epoch 32, Accuracy: 0.7490\n",
      "Epoch 33, Accuracy: 0.7568\n",
      "Epoch 34, Accuracy: 0.7578\n",
      "Epoch 35, Accuracy: 0.7812\n",
      "Epoch 36, Accuracy: 0.7656\n",
      "Epoch 37, Accuracy: 0.7656\n",
      "Epoch 38, Accuracy: 0.7744\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 37 ran for 38 epochs.\n",
      "Trial 38/50\n",
      "Epoch 1, Accuracy: 0.4404\n",
      "Epoch 2, Accuracy: 0.7207\n",
      "Epoch 3, Accuracy: 0.8096\n",
      "Epoch 4, Accuracy: 0.8301\n",
      "Epoch 5, Accuracy: 0.8340\n",
      "Epoch 6, Accuracy: 0.8623\n",
      "Epoch 7, Accuracy: 0.8447\n",
      "Epoch 8, Accuracy: 0.8760\n",
      "Epoch 9, Accuracy: 0.8760\n",
      "Epoch 10, Accuracy: 0.8721\n",
      "Epoch 11, Accuracy: 0.8779\n",
      "Epoch 12, Accuracy: 0.8809\n",
      "Epoch 13, Accuracy: 0.8809\n",
      "Epoch 14, Accuracy: 0.8926\n",
      "Epoch 15, Accuracy: 0.8848\n",
      "Epoch 16, Accuracy: 0.8896\n",
      "Epoch 17, Accuracy: 0.8691\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 38 ran for 17 epochs.\n",
      "Trial 39/50\n",
      "Epoch 1, Accuracy: 0.6182\n",
      "Epoch 2, Accuracy: 0.7930\n",
      "Epoch 3, Accuracy: 0.8350\n",
      "Epoch 4, Accuracy: 0.8682\n",
      "Epoch 5, Accuracy: 0.8584\n",
      "Epoch 6, Accuracy: 0.8887\n",
      "Epoch 7, Accuracy: 0.8672\n",
      "Epoch 8, Accuracy: 0.8945\n",
      "Epoch 9, Accuracy: 0.8887\n",
      "Epoch 10, Accuracy: 0.8984\n",
      "Epoch 11, Accuracy: 0.8984\n",
      "Epoch 12, Accuracy: 0.8955\n",
      "Epoch 13, Accuracy: 0.9033\n",
      "Epoch 14, Accuracy: 0.8936\n",
      "Epoch 15, Accuracy: 0.8887\n",
      "Epoch 16, Accuracy: 0.9131\n",
      "Epoch 17, Accuracy: 0.9033\n",
      "Epoch 18, Accuracy: 0.9043\n",
      "Epoch 19, Accuracy: 0.9277\n",
      "Epoch 20, Accuracy: 0.9199\n",
      "Epoch 21, Accuracy: 0.9180\n",
      "Epoch 22, Accuracy: 0.8984\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 39 ran for 22 epochs.\n",
      "Trial 40/50\n",
      "Epoch 1, Accuracy: 0.6406\n",
      "Epoch 2, Accuracy: 0.8477\n",
      "Epoch 3, Accuracy: 0.8682\n",
      "Epoch 4, Accuracy: 0.8906\n",
      "Epoch 5, Accuracy: 0.8711\n",
      "Epoch 6, Accuracy: 0.9004\n",
      "Epoch 7, Accuracy: 0.9014\n",
      "Epoch 8, Accuracy: 0.8984\n",
      "Epoch 9, Accuracy: 0.8955\n",
      "Epoch 10, Accuracy: 0.8994\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 40 ran for 10 epochs.\n",
      "Trial 41/50\n",
      "Epoch 1, Accuracy: 0.0947\n",
      "Epoch 2, Accuracy: 0.1055\n",
      "Epoch 3, Accuracy: 0.1094\n",
      "Epoch 4, Accuracy: 0.1377\n",
      "Epoch 5, Accuracy: 0.1475\n",
      "Epoch 6, Accuracy: 0.1553\n",
      "Epoch 7, Accuracy: 0.1602\n",
      "Epoch 8, Accuracy: 0.1748\n",
      "Epoch 9, Accuracy: 0.1621\n",
      "Epoch 10, Accuracy: 0.1621\n",
      "Epoch 11, Accuracy: 0.1914\n",
      "Epoch 12, Accuracy: 0.2012\n",
      "Epoch 13, Accuracy: 0.2100\n",
      "Epoch 14, Accuracy: 0.2295\n",
      "Epoch 15, Accuracy: 0.2598\n",
      "Epoch 16, Accuracy: 0.2559\n",
      "Epoch 17, Accuracy: 0.2715\n",
      "Epoch 18, Accuracy: 0.2930\n",
      "Epoch 19, Accuracy: 0.2988\n",
      "Epoch 20, Accuracy: 0.3428\n",
      "Epoch 21, Accuracy: 0.3477\n",
      "Epoch 22, Accuracy: 0.3164\n",
      "Epoch 23, Accuracy: 0.3848\n",
      "Epoch 24, Accuracy: 0.3730\n",
      "Epoch 25, Accuracy: 0.3740\n",
      "Epoch 26, Accuracy: 0.3857\n",
      "Epoch 27, Accuracy: 0.3652\n",
      "Epoch 28, Accuracy: 0.4033\n",
      "Epoch 29, Accuracy: 0.4082\n",
      "Epoch 30, Accuracy: 0.4072\n",
      "Epoch 31, Accuracy: 0.4053\n",
      "Epoch 32, Accuracy: 0.4492\n",
      "Epoch 33, Accuracy: 0.4287\n",
      "Epoch 34, Accuracy: 0.4746\n",
      "Epoch 35, Accuracy: 0.4609\n",
      "Epoch 36, Accuracy: 0.4619\n",
      "Epoch 37, Accuracy: 0.4453\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 41 ran for 37 epochs.\n",
      "Trial 42/50\n",
      "Epoch 1, Accuracy: 0.1660\n",
      "Epoch 2, Accuracy: 0.2500\n",
      "Epoch 3, Accuracy: 0.3242\n",
      "Epoch 4, Accuracy: 0.4111\n",
      "Epoch 5, Accuracy: 0.4688\n",
      "Epoch 6, Accuracy: 0.5771\n",
      "Epoch 7, Accuracy: 0.6191\n",
      "Epoch 8, Accuracy: 0.7031\n",
      "Epoch 9, Accuracy: 0.7178\n",
      "Epoch 10, Accuracy: 0.7510\n",
      "Epoch 11, Accuracy: 0.7588\n",
      "Epoch 12, Accuracy: 0.7773\n",
      "Epoch 13, Accuracy: 0.7930\n",
      "Epoch 14, Accuracy: 0.8213\n",
      "Epoch 15, Accuracy: 0.8018\n",
      "Epoch 16, Accuracy: 0.8408\n",
      "Epoch 17, Accuracy: 0.8496\n",
      "Epoch 18, Accuracy: 0.8545\n",
      "Epoch 19, Accuracy: 0.8496\n",
      "Epoch 20, Accuracy: 0.8477\n",
      "Epoch 21, Accuracy: 0.8389\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 42 ran for 21 epochs.\n",
      "Trial 43/50\n",
      "Epoch 1, Accuracy: 0.1416\n",
      "Epoch 2, Accuracy: 0.2217\n",
      "Epoch 3, Accuracy: 0.3066\n",
      "Epoch 4, Accuracy: 0.4072\n",
      "Epoch 5, Accuracy: 0.4580\n",
      "Epoch 6, Accuracy: 0.5088\n",
      "Epoch 7, Accuracy: 0.5322\n",
      "Epoch 8, Accuracy: 0.5664\n",
      "Epoch 9, Accuracy: 0.6309\n",
      "Epoch 10, Accuracy: 0.6836\n",
      "Epoch 11, Accuracy: 0.6719\n",
      "Epoch 12, Accuracy: 0.7119\n",
      "Epoch 13, Accuracy: 0.7178\n",
      "Epoch 14, Accuracy: 0.7422\n",
      "Epoch 15, Accuracy: 0.7275\n",
      "Epoch 16, Accuracy: 0.7617\n",
      "Epoch 17, Accuracy: 0.7734\n",
      "Epoch 18, Accuracy: 0.8008\n",
      "Epoch 19, Accuracy: 0.8145\n",
      "Epoch 20, Accuracy: 0.7998\n",
      "Epoch 21, Accuracy: 0.8154\n",
      "Epoch 22, Accuracy: 0.8164\n",
      "Epoch 23, Accuracy: 0.8262\n",
      "Epoch 24, Accuracy: 0.8340\n",
      "Epoch 25, Accuracy: 0.8320\n",
      "Epoch 26, Accuracy: 0.8369\n",
      "Epoch 27, Accuracy: 0.8359\n",
      "Epoch 28, Accuracy: 0.8516\n",
      "Epoch 29, Accuracy: 0.8428\n",
      "Epoch 30, Accuracy: 0.8564\n",
      "Epoch 31, Accuracy: 0.8564\n",
      "Epoch 32, Accuracy: 0.8643\n",
      "Epoch 33, Accuracy: 0.8271\n",
      "Epoch 34, Accuracy: 0.8750\n",
      "Epoch 35, Accuracy: 0.8398\n",
      "Epoch 36, Accuracy: 0.8408\n",
      "Epoch 37, Accuracy: 0.8691\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 43 ran for 37 epochs.\n",
      "Trial 44/50\n",
      "Epoch 1, Accuracy: 0.1953\n",
      "Epoch 2, Accuracy: 0.2881\n",
      "Epoch 3, Accuracy: 0.4121\n",
      "Epoch 4, Accuracy: 0.5771\n",
      "Epoch 5, Accuracy: 0.6826\n",
      "Epoch 6, Accuracy: 0.7354\n",
      "Epoch 7, Accuracy: 0.7695\n",
      "Epoch 8, Accuracy: 0.8086\n",
      "Epoch 9, Accuracy: 0.8213\n",
      "Epoch 10, Accuracy: 0.8301\n",
      "Epoch 11, Accuracy: 0.8477\n",
      "Epoch 12, Accuracy: 0.8340\n",
      "Epoch 13, Accuracy: 0.8516\n",
      "Epoch 14, Accuracy: 0.8623\n",
      "Epoch 15, Accuracy: 0.8652\n",
      "Epoch 16, Accuracy: 0.8770\n",
      "Epoch 17, Accuracy: 0.8662\n",
      "Epoch 18, Accuracy: 0.8955\n",
      "Epoch 19, Accuracy: 0.8643\n",
      "Epoch 20, Accuracy: 0.8760\n",
      "Epoch 21, Accuracy: 0.8984\n",
      "Epoch 22, Accuracy: 0.8662\n",
      "Epoch 23, Accuracy: 0.8779\n",
      "Epoch 24, Accuracy: 0.8945\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 44 ran for 24 epochs.\n",
      "Trial 45/50\n",
      "Epoch 1, Accuracy: 0.2100\n",
      "Epoch 2, Accuracy: 0.4609\n",
      "Epoch 3, Accuracy: 0.6689\n",
      "Epoch 4, Accuracy: 0.7344\n",
      "Epoch 5, Accuracy: 0.7852\n",
      "Epoch 6, Accuracy: 0.7822\n",
      "Epoch 7, Accuracy: 0.8262\n",
      "Epoch 8, Accuracy: 0.8311\n",
      "Epoch 9, Accuracy: 0.8281\n",
      "Epoch 10, Accuracy: 0.8262\n",
      "Epoch 11, Accuracy: 0.8555\n",
      "Epoch 12, Accuracy: 0.8604\n",
      "Epoch 13, Accuracy: 0.8525\n",
      "Epoch 14, Accuracy: 0.8535\n",
      "Epoch 15, Accuracy: 0.8564\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 45 ran for 15 epochs.\n",
      "Trial 46/50\n",
      "Epoch 1, Accuracy: 0.0879\n",
      "Epoch 2, Accuracy: 0.1172\n",
      "Epoch 3, Accuracy: 0.1416\n",
      "Epoch 4, Accuracy: 0.1777\n",
      "Epoch 5, Accuracy: 0.1982\n",
      "Epoch 6, Accuracy: 0.2295\n",
      "Epoch 7, Accuracy: 0.2578\n",
      "Epoch 8, Accuracy: 0.2969\n",
      "Epoch 9, Accuracy: 0.3105\n",
      "Epoch 10, Accuracy: 0.3213\n",
      "Epoch 11, Accuracy: 0.3545\n",
      "Epoch 12, Accuracy: 0.3682\n",
      "Epoch 13, Accuracy: 0.3545\n",
      "Epoch 14, Accuracy: 0.3682\n",
      "Epoch 15, Accuracy: 0.3994\n",
      "Epoch 16, Accuracy: 0.4629\n",
      "Epoch 17, Accuracy: 0.4766\n",
      "Epoch 18, Accuracy: 0.4785\n",
      "Epoch 19, Accuracy: 0.5303\n",
      "Epoch 20, Accuracy: 0.5205\n",
      "Epoch 21, Accuracy: 0.5381\n",
      "Epoch 22, Accuracy: 0.5498\n",
      "Epoch 23, Accuracy: 0.6006\n",
      "Epoch 24, Accuracy: 0.5977\n",
      "Epoch 25, Accuracy: 0.6357\n",
      "Epoch 26, Accuracy: 0.6143\n",
      "Epoch 27, Accuracy: 0.6455\n",
      "Epoch 28, Accuracy: 0.6445\n",
      "Epoch 29, Accuracy: 0.6631\n",
      "Epoch 30, Accuracy: 0.7051\n",
      "Epoch 31, Accuracy: 0.6875\n",
      "Epoch 32, Accuracy: 0.6689\n",
      "Epoch 33, Accuracy: 0.6904\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 46 ran for 33 epochs.\n",
      "Trial 47/50\n",
      "Epoch 1, Accuracy: 0.5117\n",
      "Epoch 2, Accuracy: 0.7695\n",
      "Epoch 3, Accuracy: 0.8428\n",
      "Epoch 4, Accuracy: 0.8535\n",
      "Epoch 5, Accuracy: 0.8809\n",
      "Epoch 6, Accuracy: 0.8857\n",
      "Epoch 7, Accuracy: 0.8916\n",
      "Epoch 8, Accuracy: 0.8838\n",
      "Epoch 9, Accuracy: 0.8955\n",
      "Epoch 10, Accuracy: 0.8955\n",
      "Epoch 11, Accuracy: 0.8945\n",
      "Epoch 12, Accuracy: 0.8877\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 47 ran for 12 epochs.\n",
      "Trial 48/50\n",
      "Epoch 1, Accuracy: 0.3506\n",
      "Epoch 2, Accuracy: 0.5703\n",
      "Epoch 3, Accuracy: 0.7002\n",
      "Epoch 4, Accuracy: 0.7959\n",
      "Epoch 5, Accuracy: 0.8154\n",
      "Epoch 6, Accuracy: 0.8281\n",
      "Epoch 7, Accuracy: 0.8418\n",
      "Epoch 8, Accuracy: 0.8496\n",
      "Epoch 9, Accuracy: 0.8643\n",
      "Epoch 10, Accuracy: 0.8555\n",
      "Epoch 11, Accuracy: 0.8594\n",
      "Epoch 12, Accuracy: 0.8848\n",
      "Epoch 13, Accuracy: 0.8652\n",
      "Epoch 14, Accuracy: 0.8887\n",
      "Epoch 15, Accuracy: 0.8867\n",
      "Epoch 16, Accuracy: 0.8662\n",
      "Epoch 17, Accuracy: 0.8770\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 48 ran for 17 epochs.\n",
      "Trial 49/50\n",
      "Epoch 1, Accuracy: 0.8145\n",
      "Epoch 2, Accuracy: 0.8906\n",
      "Epoch 3, Accuracy: 0.9004\n",
      "Epoch 4, Accuracy: 0.8975\n",
      "Epoch 5, Accuracy: 0.9189\n",
      "Epoch 6, Accuracy: 0.9150\n",
      "Epoch 7, Accuracy: 0.9219\n",
      "Epoch 8, Accuracy: 0.9307\n",
      "Epoch 9, Accuracy: 0.9248\n",
      "Epoch 10, Accuracy: 0.9492\n",
      "Epoch 11, Accuracy: 0.9307\n",
      "Epoch 12, Accuracy: 0.9453\n",
      "Epoch 13, Accuracy: 0.9395\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 49 ran for 13 epochs.\n",
      "Trial 50/50\n",
      "Epoch 1, Accuracy: 0.1592\n",
      "Epoch 2, Accuracy: 0.2471\n",
      "Epoch 3, Accuracy: 0.3662\n",
      "Epoch 4, Accuracy: 0.4814\n",
      "Epoch 5, Accuracy: 0.5811\n",
      "Epoch 6, Accuracy: 0.6318\n",
      "Epoch 7, Accuracy: 0.7275\n",
      "Epoch 8, Accuracy: 0.7402\n",
      "Epoch 9, Accuracy: 0.7852\n",
      "Epoch 10, Accuracy: 0.7852\n",
      "Epoch 11, Accuracy: 0.8252\n",
      "Epoch 12, Accuracy: 0.8232\n",
      "Epoch 13, Accuracy: 0.8232\n",
      "Epoch 14, Accuracy: 0.8584\n",
      "Epoch 15, Accuracy: 0.8457\n",
      "Epoch 16, Accuracy: 0.8574\n",
      "Epoch 17, Accuracy: 0.8477\n",
      "Early stopping triggered after 3 epochs with no improvement.\n",
      "Trial 50 ran for 17 epochs.\n",
      "\n",
      "Best configuration: {'lr': 0.006910837996089555, 'momentum': 0.5694496015059088, 'epochs': 16}\n",
      "Best accuracy: 0.9414\n",
      "Total execution time: 1542.48 seconds\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import tempfile\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from filelock import FileLock\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Change these values if you want the training to run quicker or slower.\n",
    "EPOCH_SIZE = 6000\n",
    "TEST_SIZE = 1000\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 3, kernel_size=3)\n",
    "        self.fc = nn.Linear(192, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 3))\n",
    "        x = x.view(-1, 192)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "def train_func(model, optimizer, train_loader, device=None):\n",
    "    device = device or torch.device(\"cpu\")\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if batch_idx * len(data) > EPOCH_SIZE:\n",
    "            return\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def test_func(model, data_loader, device=None):\n",
    "    device = device or torch.device(\"cpu\")\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            if batch_idx * len(data) > TEST_SIZE:\n",
    "                break\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "def get_data_loaders(batch_size=64):\n",
    "    mnist_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "    )\n",
    "\n",
    "    # We add FileLock here because multiple workers will want to\n",
    "    # download data, and this may cause overwrites since\n",
    "    # DataLoader is not threadsafe.\n",
    "    with FileLock(os.path.expanduser(\"~/data.lock\")):\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST(\n",
    "                \"~/data\", train=True, download=True, transform=mnist_transforms\n",
    "            ),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            datasets.MNIST(\n",
    "                \"~/data\", train=False, download=True, transform=mnist_transforms\n",
    "            ),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def train_mnist(config):\n",
    "    should_checkpoint = config.get(\"should_checkpoint\", False)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    train_loader, test_loader = get_data_loaders()\n",
    "    model = ConvNet().to(device)\n",
    "\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"]\n",
    "    )\n",
    "\n",
    "    # Early stopping parameters\n",
    "    patience = config.get(\"patience\", 3)  # How many epochs to wait before stopping\n",
    "    best_acc = 0.0  # Start with the best accuracy being 0\n",
    "    epochs_without_improvement = 0\n",
    "    epochs_run = 0  # Variable to track the number of epochs run\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(config.get(\"epochs\", 10)):  # Default to 10 epochs\n",
    "        epochs_run += 1\n",
    "        train_func(model, optimizer, train_loader, device)\n",
    "        acc = test_func(model, test_loader, device)\n",
    "        metrics = {\"mean_accuracy\": acc}\n",
    "        print(f\"Epoch {epoch + 1}, Accuracy: {acc:.4f}\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            epochs_without_improvement = 0  # Reset counter if accuracy improves\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        # If no improvement for 'patience' epochs, stop early\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping triggered after {patience} epochs with no improvement.\")\n",
    "            break\n",
    "\n",
    "        if should_checkpoint:\n",
    "            with tempfile.TemporaryDirectory() as tempdir:\n",
    "                torch.save(model.state_dict(), os.path.join(tempdir, \"model.pt\"))\n",
    "                # Save checkpoint logic here (if needed, e.g., for Ray)\n",
    "                # train.report(metrics, checkpoint=Checkpoint.from_directory(tempdir))\n",
    "        else:\n",
    "            # Report metrics\n",
    "            pass\n",
    "\n",
    "    # Save the actual number of epochs run for the trial\n",
    "    config[\"epochs\"] = epochs_run\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def sample_hyperparameters(num_samples):\n",
    "    \"\"\"Samples hyperparameters from the same distributions as Ray.\"\"\"\n",
    "    lrs = np.exp(np.random.uniform(np.log(1e-4), np.log(1e-2), size=num_samples))  # log scale\n",
    "    momentums = np.random.uniform(0.1, 0.9, size=num_samples)  # uniform\n",
    "    return [{\"lr\": lr, \"momentum\": momentum} for lr, momentum in zip(lrs, momentums)]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()  # Start measuring time\n",
    "    \n",
    "    num_trials = 50\n",
    "    best_accuracy = 0\n",
    "    best_config = None\n",
    "\n",
    "    # Sample 50 hyperparameter configurations\n",
    "    hyperparameter_configs = sample_hyperparameters(num_samples=num_trials)\n",
    "\n",
    "    for trial_idx, config in enumerate(hyperparameter_configs):\n",
    "        print(f\"Trial {trial_idx + 1}/{num_trials}\")\n",
    "        config[\"epochs\"] = 100  # Number of epochs for each trial\n",
    "        metrics = train_mnist(config)\n",
    "        \n",
    "        # Update the best accuracy and config if needed\n",
    "        if metrics[\"mean_accuracy\"] > best_accuracy:\n",
    "            best_accuracy = metrics[\"mean_accuracy\"]\n",
    "            best_config = config\n",
    "\n",
    "        # Print the number of epochs executed for the trial\n",
    "        print(f\"Trial {trial_idx + 1} ran for {config['epochs']} epochs.\")\n",
    "\n",
    "    print(f\"\\nBest configuration: {best_config}\")\n",
    "    print(f\"Best accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "    total_time = time.time() - start_time  # Total script time\n",
    "    print(f\"Total execution time: {total_time:.2f} seconds\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
